{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94e6982",
   "metadata": {},
   "source": [
    "# Hands On: Seleksi Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a24fd",
   "metadata": {},
   "source": [
    "Seringkali Anda akan memiliki ratusan atau ribuan fitur setelah berbagai penyandian dan pembuatan fitur. Hal ini dapat menyebabkan dua masalah. \n",
    "\n",
    "Pertama, semakin banyak fitur yang Anda miliki, semakin besar kemungkinan Anda menyesuaikan diri dengan set pelatihan dan validasi. Ini akan menyebabkan model Anda berkinerja lebih buruk dalam menggeneralisasi ke data baru.\n",
    "\n",
    "Kedua, semakin banyak fitur yang Anda miliki, semakin lama waktu yang dibutuhkan untuk melatih model Anda dan mengoptimalkan hyperparameter. Selain itu, saat membuat produk yang menghadap pengguna, Anda harus membuat inferensi secepat mungkin. Menggunakan lebih sedikit fitur dapat mempercepat inferensi dengan mengorbankan kinerja prediktif.\n",
    "\n",
    "Untuk membantu mengatasi masalah ini, Anda sebaiknya menggunakan teknik pemilihan fitur untuk mempertahankan fitur yang paling informatif untuk model Anda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8003b",
   "metadata": {},
   "source": [
    "Seleksi fitur (feature selection) adalah proses memilih feature yang tepat untuk melatih model ML. \n",
    "\n",
    "Untuk melakukan feature selection, kita perlu memahami hubungan antara variables.\n",
    "Hubungan antar dua random variables disebut correlation dan dapat dihitung dengan menggunakan correlation coefficient.\n",
    "\n",
    "Range nilai correlation coeficient adalah:\n",
    "\n",
    "Positif maks +1, korelasi positif, artinya kedua variable akan bergerak searah.\n",
    "Negatif maks -1, korelasi negatif, artinya kedua variable akan bergerak berlawanan.\n",
    "Nol, menunjukan antara kedua variable tidak ada correlation.\n",
    "Teknik perhitungan correlation cukup banyak, berikut yang umum digunakan: Pearson, Kendall dan Spearman.\n",
    "\n",
    "A. Pearson\n",
    "* Paling umum digunakan.\n",
    "* Digunakan untuk numerical data.\n",
    "* Tidak bisa digunakan untuk ordinal data.\n",
    "* Mengukur linear data dengan asumsi data terdistribusi normal.\n",
    "\n",
    "B. Kendall\n",
    "* Rank correlation measure.\n",
    "* Dapat digunakan untuk numerical dan ordinal data, namun tidak untuk nominal data.\n",
    "* Tidak diperlukan linear relationship antar variable.\n",
    "* Digunakan untuk mengukur kemiripan ranked ordering data.\n",
    "* Untuk kondisi normal lebih baik menggunakan Kendall dibandingkan Spearman.\n",
    "\n",
    "C. Spearman\n",
    "* Rank correlation measure\n",
    "* Dapat digunakan untuk numerical dan ordinal data, namun tidak untuk nominal data.\n",
    "* Tidak diperlukan linear relationship antar variable.\n",
    "* Monotonic relationship\n",
    "\n",
    "Ada beberapa metoda feature selection yang umum digunakan, yaitu Filter, Embedded dan Wrapper.\n",
    "\n",
    "**Filter Method**\n",
    "Umumnya digunakan pada tahap preprocessing. Pemilihan features tidak tergantung kepada algoritma ML yang akan digunakan . Features dipilih berdasarkan score test statistik kolerasi.\n",
    "\n",
    "**Embedded Method**\n",
    "Feature dipilih saat proses model training. Menggunakan learning algorithm untuk melakukan variable selection dan feature selection and classification secara simultan. Harus memilih algoritma machine learning yang sesuai.\n",
    "\n",
    "**Wrapper Method**\n",
    "Menggunakan subset of features untuk melatih model. Berdasarkan hasil yang dihasilkan dari model sebelumnya, kita tentukan untuk menambah atau membuang features dari subset. Kelemahannya membutuhkan resource besar dalam melakukan komputasi.\n",
    "\n",
    "Ada jenis seleksi fitur lainnya, seperti dalam slide modul 8 ini, diantaranya:\n",
    "1. Seleksi Univariat (Univariate Selection)\n",
    "2. Pentingnya Fitur (Feature Importance)\n",
    "3. Matriks Korelasi (Correlation Matrix) dengan Heatmap\n",
    "\n",
    "Teknik pemilihan fitur yang perlu kita ketahui, untuk mendapatkan performa terbaik dari model Anda.\n",
    "\n",
    "1. SelectKBest\n",
    "2. Regresi linier\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "5. Penghapusan Fitur Rekursif\n",
    "6. Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb966f",
   "metadata": {},
   "source": [
    "### Berikut ini adalah sebagian kecil dari metode/teknik dalam Seleksi Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a056c61",
   "metadata": {},
   "source": [
    "#### Sumber dataset: \n",
    "---\n",
    "\n",
    "https://www.kaggle.com/iabhishekofficial/mobile-price-classification#train.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575259c",
   "metadata": {},
   "source": [
    "#### Deskripsi variabel dari dataset:\n",
    "\n",
    "* battery_power: Total energy a battery can store in one time measured in mAh\n",
    "* blue: Has Bluetooth or not\n",
    "* clock_speed: the speed at which microprocessor executes instructions\n",
    "* dual_sim: Has dual sim support or not\n",
    "* fc: Front Camera megapixels\n",
    "* four_g: Has 4G or not\n",
    "* int_memory: Internal Memory in Gigabytes\n",
    "* m_dep: Mobile Depth in cm\n",
    "* mobile_wt: Weight of mobile phone\n",
    "* n_cores: Number of cores of the processor\n",
    "* pc: Primary Camera megapixels\n",
    "* px_height: Pixel Resolution Height\n",
    "* px_width: Pixel Resolution Width\n",
    "* ram: Random Access Memory in MegaBytes\n",
    "* sc_h: Screen Height of mobile in cm\n",
    "* sc_w: Screen Width of mobile in cm\n",
    "* talk_time: the longest time that a single battery charge will last when you are\n",
    "* three_g: Has 3G or not\n",
    "* touch_screen: Has touch screen or not\n",
    "* wifi: Has wifi or not\n",
    "* price_range: This is the target variable with a value of 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455ae5e",
   "metadata": {},
   "source": [
    "### 1. Seleksi Unvariate\n",
    "---\n",
    "Metode paling sederhana dan tercepat didasarkan pada uji statistik univariat. Untuk setiap fitur, ukur seberapa kuat target bergantung pada fitur menggunakan uji statistik seperti  Ï‡2 (chi-square) or ANOVA.\n",
    "\n",
    "Uji statistik dapat digunakan untuk memilih fitur-fitur tersebut yang memiliki relasi paling kuat dengan variabel output/target.\n",
    "Library scikit-learn menyediakan class *SelectKBest* yang digunakan untuk serangkaian uji statistik berbeda untuk memilih angka spesifik dari fitur. Berikut ini adalah uji statistik chi-square utk fitur non-negatif untuk memilih 10 fitur terbaik dari dataset *Mobile Price Range Prediction*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749080a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = data.iloc[:,0:20]  #independent colums\n",
    "y = data.iloc[:,-1]    # target colum i.e price range\n",
    "\n",
    "# apply SelectKBest class to extract\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17648005",
   "metadata": {},
   "source": [
    "### 2. Feature Importance\n",
    "---\n",
    "*Feature importance* mengacu pada kelas teknik untuk menetapkan skor ke fitur input ke model prediktif yang menunjukkan *importance* relatif dari setiap fitur saat membuat prediksi.\n",
    "\n",
    "Skor *Feature importance* dapat dihitung untuk masalah yang melibatkan prediksi nilai numerik, yang disebut regresi, dan masalah yang melibatkan prediksi label kelas, yang disebut klasifikasi.\n",
    "\n",
    "Skor berguna dan dapat digunakan dalam berbagai situasi dalam masalah pemodelan prediktif, seperti:\n",
    "\n",
    "* Lebih memahami data.\n",
    "* Lebih memahami model.\n",
    "* Mengurangi jumlah fitur input.\n",
    "* memberi  skor untuk setiap fitur data, semakin tinggi skor semakin penting atau relevan fitur tersebut terhadap variabel output\n",
    "\n",
    "inbuilt yang dilengkapi dengan Pengklasifikasi Berbasis Pohon (Tree Based Classifier), kami akan menggunakan Pengklasifikasi Pohon Ekstra untuk mengekstraksi 10 fitur teratas untuk kumpulan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37905c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "X = data.iloc[:,0:20]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a01da9",
   "metadata": {},
   "source": [
    "### 3. Matriks Korelasi dengan Heatmap\n",
    "---\n",
    "\n",
    "* Korelasi menyatakan bagaimana fitur terkait satu sama lain atau variabel target.\n",
    "* Korelasi bisa positif (kenaikan satu nilai fitur meningkatkan nilai variabel target) atau negatif (kenaikan satu nilai fitur menurunkan nilai variabel target)\n",
    "* Heatmap memudahkan untuk mengidentifikasi fitur mana yang paling terkait dengan variabel target, kami akan memplot peta panas fitur yang berkorelasi menggunakan seaborn library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = data.iloc[:,0:20]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "#get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2b58f",
   "metadata": {},
   "source": [
    "### Matriks Korelasi dengan Heatmap (lanjutan)\n",
    "---\n",
    "\n",
    "\n",
    "* lihat pada baris terakhir yaitu price range, korelasi antara price range dengan fitur lain dimana ada relasi kuat dengan variabel  ram dan diikuti oleh var battery power ,  px height and px width.\n",
    "* sedangkan utk var clock_speed dan n_cores berkorelasi lemah dengan price range\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
